{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Custom vs. Scikit learn Built Decision Tree"
      ],
      "metadata": {
        "id": "QI2E65-d5ndT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Buld a Custom Decision Tree"
      ],
      "metadata": {
        "id": "7uIyiQsd53sk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fW-OvrOr_1b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class CustomDecisionTree:\n",
        "    def __init__(self, max_depth=None):\n",
        "        self.max_depth = max_depth\n",
        "        self.tree = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.tree = self._build_tree(X, y)\n",
        "\n",
        "    def _build_tree(self, X, y, depth=0):\n",
        "        num_samples, num_features = X.shape\n",
        "        unique_classes = np.unique(y)\n",
        "\n",
        "        if len(unique_classes) == 1:\n",
        "            return {'class': unique_classes[0]}\n",
        "\n",
        "        if num_samples == 0 or (self.max_depth and depth >= self.max_depth):\n",
        "            return {'class': np.bincount(y).argmax()}\n",
        "\n",
        "        best_info_gain = -float('inf')\n",
        "        best_split = None\n",
        "        for feature_idx in range(num_features):\n",
        "            thresholds = np.unique(X[:, feature_idx])\n",
        "            for threshold in thresholds:\n",
        "                left_mask = X[:, feature_idx] <= threshold\n",
        "                right_mask = ~left_mask\n",
        "                left_y, right_y = y[left_mask], y[right_mask]\n",
        "                info_gain = self._information_gain(y, left_y, right_y)\n",
        "\n",
        "                if info_gain > best_info_gain:\n",
        "                    best_info_gain = info_gain\n",
        "                    best_split = {\n",
        "                        'feature_idx': feature_idx,\n",
        "                        'threshold': threshold,\n",
        "                        'left_y': left_y,\n",
        "                        'right_y': right_y,\n",
        "                    }\n",
        "\n",
        "        if best_split is None:\n",
        "            return {'class': np.bincount(y).argmax()}\n",
        "\n",
        "        left_tree = self._build_tree(X[best_split['left_y']], best_split['left_y'], depth + 1)\n",
        "        right_tree = self._build_tree(X[best_split['right_y']], best_split['right_y'], depth + 1)\n",
        "\n",
        "        return {'feature_idx': best_split['feature_idx'], 'threshold': best_split['threshold'],\n",
        "                'left_tree': left_tree, 'right_tree': right_tree}\n",
        "\n",
        "    def _information_gain(self, parent, left, right):\n",
        "        parent_entropy = self._entropy(parent)\n",
        "        left_entropy = self._entropy(left)\n",
        "        right_entropy = self._entropy(right)\n",
        "\n",
        "        weighted_avg_entropy = (len(left) / len(parent)) * left_entropy + (len(right) / len(parent)) * right_entropy\n",
        "        return parent_entropy - weighted_avg_entropy\n",
        "\n",
        "    def _entropy(self, y):\n",
        "        class_probs = np.bincount(y) / len(y)\n",
        "        return -np.sum(class_probs * np.log2(class_probs + 1e-9))  # epsilon to avoid log(0)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return [self._predict_single(x, self.tree) for x in X]\n",
        "\n",
        "    def _predict_single(self, x, tree):\n",
        "        if 'class' in tree:\n",
        "            return tree['class']\n",
        "        feature_val = x[tree['feature_idx']]\n",
        "        if feature_val <= tree['threshold']:\n",
        "            return self._predict_single(x, tree['left_tree'])\n",
        "        else:\n",
        "            return self._predict_single(x, tree['right_tree'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Necessary Imports"
      ],
      "metadata": {
        "id": "XU15GZcWsJDM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "-g3DdwQksGsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and Split the Iris Dataset"
      ],
      "metadata": {
        "id": "UxZTUicosMvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Iris dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split into training and test sets (80% training, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ThUBcB5xsA8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and Evaluate the Custom Decision Tree"
      ],
      "metadata": {
        "id": "4dGanBWusT01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the custom decision tree\n",
        "custom_tree = CustomDecisionTree(max_depth=3)\n",
        "custom_tree.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_custom = custom_tree.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_custom = accuracy_score(y_test, y_pred_custom)\n",
        "print(f\"Custom Decision Tree Accuracy: {accuracy_custom:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKs5ce4msXYk",
        "outputId": "74e5b3c5-6b94-4826-fa62-bdfca8893caa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom Decision Tree Accuracy: 0.8000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and Evaluate the scikit-learn Decision Tree"
      ],
      "metadata": {
        "id": "DETmEUtuseDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Scikit-learn decision tree\n",
        "sklearn_tree = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "sklearn_tree.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_sklearn = sklearn_tree.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_sklearn = accuracy_score(y_test, y_pred_sklearn)\n",
        "print(f\"Scikit-learn Decision Tree Accuracy: {accuracy_sklearn:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8wPUUMusYoR",
        "outputId": "3b69da73-d0b6-4d18-f5da-1451dc56d9c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scikit-learn Decision Tree Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Result Comparision"
      ],
      "metadata": {
        "id": "Dx8YHB4uspeD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Accuracy Comparison:\")\n",
        "print(f\"Custom Decision Tree: {accuracy_custom:.4f}\")\n",
        "print(f\"Scikit-learn Decision Tree: {accuracy_sklearn:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yN97p23DsngA",
        "outputId": "981ef77a-d36e-4af9-9866-9ca1693cdfe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Comparison:\n",
            "Custom Decision Tree: 0.8000\n",
            "Scikit-learn Decision Tree: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the Wine dataset\n",
        "wine_data = load_wine()\n",
        "X_train, X_test, y_train, y_test = train_test_split(wine_data.data, wine_data.target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Decision Tree Classifier\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "f1_dt = f1_score(y_test, dt_classifier.predict(X_test), average='weighted')\n",
        "print(f\"Decision Tree F1 Score: {f1_dt:.4f}\")\n",
        "\n",
        "# Train a Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "f1_rf = f1_score(y_test, rf_classifier.predict(X_test), average='weighted')\n",
        "print(f\"Random Forest F1 Score: {f1_rf:.4f}\")\n"
      ],
      "metadata": {
        "id": "-ryh0U9OssqQ",
        "outputId": "4223db24-e95d-4901-d496-f2ff72dff584",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree F1 Score: 0.9440\n",
            "Random Forest F1 Score: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Hyperparameter tuning for Random Forest using GridSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [5, 10, 15],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best Params: {grid_search.best_params_}\")\n",
        "print(f\"Best Cross-validation Score: {grid_search.best_score_:.4f}\")\n"
      ],
      "metadata": {
        "id": "OQQuJYjARCZS",
        "outputId": "07f6ae92-2ec4-4fd1-a9eb-b313de7b54c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Params: {'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "Best Cross-validation Score: 0.9786\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load California housing dataset\n",
        "housing_data = fetch_california_housing()\n",
        "X_train, X_test, y_train, y_test = train_test_split(housing_data.data, housing_data.target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Decision Tree Regressor\n",
        "dt_regressor = DecisionTreeRegressor(random_state=42)\n",
        "dt_regressor.fit(X_train, y_train)\n",
        "mse_dt = mean_squared_error(y_test, dt_regressor.predict(X_test))\n",
        "print(f\"Decision Tree Regressor MSE: {mse_dt:.4f}\")\n",
        "\n",
        "# Train Random Forest Regressor\n",
        "rf_regressor = RandomForestRegressor(random_state=42)\n",
        "rf_regressor.fit(X_train, y_train)\n",
        "mse_rf = mean_squared_error(y_test, rf_regressor.predict(X_test))\n",
        "print(f\"Random Forest Regressor MSE: {mse_rf:.4f}\")\n"
      ],
      "metadata": {
        "id": "pCag8x7gRFdb",
        "outputId": "a70762ee-ecd5-48e7-eb12-1e41b2695691",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Regressor MSE: 0.4952\n",
            "Random Forest Regressor MSE: 0.2554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data = load_wine()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100],\n",
        "    'max_depth': [5, 10],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    RandomForestRegressor(random_state=42),\n",
        "    param_dist,\n",
        "    n_iter=5,\n",
        "    cv=3,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best Params: {random_search.best_params_}\")\n",
        "print(f\"Best Cross-validation Score: {random_search.best_score_:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "abVnzTqmRJMP",
        "outputId": "81290d2f-d56a-43fb-d919-695fa00a6cf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Params: {'n_estimators': 50, 'min_samples_split': 2, 'max_depth': 5}\n",
            "Best Cross-validation Score: 0.9057\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JQzUCP7sS_QE"
      }
    }
  ]
}